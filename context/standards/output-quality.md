# Output Quality Standards

## Purpose
Define what constitutes high-quality analysis and recommendations from this system.

---

## Analysis Quality Criteria

### ✅ Good Analysis Includes:
- Specific scoring on all 4 framework pillars
- Evidence for each score (examples from content)
- Comparison to competitor performance
- Clear identification of gaps
- Prioritized recommendations
- Actionable next steps

### ❌ Poor Analysis Includes:
- Vague observations ("content could be better")
- Scores without justification
- Generic recommendations
- No competitive context
- Unclear priorities
- Recommendations that can't be implemented

---

## Recommendation Standards

Every recommendation must include:

1. **What:** Specific change to make
2. **Where:** Exact location in content
3. **Why:** Framework-based reasoning
4. **Impact:** Expected improvement
5. **Priority:** High/Medium/Low with justification

**Example Good Recommendation:**
```
WHAT: Add specific ROI metrics to case study section
WHERE: "Customer Success Stories" section, ABC Company case study
WHY: Statistical Specificity score is 4/10; competitors average 8/10
      with concrete metrics. Missing data points: time to value, 
      cost savings, efficiency gains.
IMPACT: Estimated 15-20% increase in citation rate based on 
        competitor analysis
PRIORITY: HIGH - lowest-scoring pillar with clearest path to improvement
```

**Example Poor Recommendation:**
```
"Add more data"  ❌ Too vague
"Improve content quality"  ❌ No specificity
"Be more authoritative"  ❌ Not actionable
```

---

## Scoring Consistency

When scoring content:
- Use the full 0-10 range
- Provide specific examples for the score given
- Compare to framework criteria explicitly
- Be consistent across similar content types
- Don't inflate scores (honest assessment drives improvement)

**Scoring Template:**
```
[Pillar Name]: [Score]/10

Evidence:
- [Specific example supporting score]
- [Specific example supporting score]

Gap Analysis:
- [What's missing to reach higher score]
- [Comparison to high-scoring content]
```

---

## Report Structure Standard

All citation analysis reports should follow this structure:

1. **Executive Summary** (2-3 sentences)
   - Current citation status
   - Biggest gap identified
   - Top priority recommendation

2. **Citation Status**
   - Platform-by-platform breakdown
   - Competitor comparison
   - Trend data (if available)

3. **Framework Assessment**
   - All 4 pillar scores with evidence
   - Strengths and weaknesses
   - Patterns across content

4. **Competitive Analysis**
   - What competitors do better
   - What we do better
   - Specific examples of citation-winning content

5. **Recommendations**
   - Prioritized list (High/Med/Low)
   - Each with What/Where/Why/Impact
   - Estimated timeline for implementation

6. **Next Actions**
   - Specific tasks with owners
   - Success metrics
   - Follow-up schedule

---

*Maintain these standards for all outputs from this system*